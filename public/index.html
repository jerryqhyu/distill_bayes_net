<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=1080">

<!-- <script src="https://distill.pub/template.v1.js"></script> -->
<script src="assets/lib/template.v1.js"></script>
<script src="assets/lib/d3.v4.min.js"></script>
<script src="assets/lib/d3-contour.v1.min.js"></script>
<script src="assets/lib/d3-scale-chromatic.v1.min.js"></script>
<script src="assets/lib/katex.min.js"></script>
<script src="assets/lib/auto-render.min.js"></script>
<link rel="stylesheet" href="assets/lib/katex.min.css">
<link rel="stylesheet" type="text/css" href="assets/widgets.css">

<script type="text/front-matter">
    title: "Bayesian Neural Networks"
    description: "How do we prevent neural networks from overfitting? We can avoid trying to choose a single best set of weights, and instead average over all posible weights!"
    authors:
    - Jerry Qinghui Yu: http://www.cs.toronto.edu/~jerry/
    - David Duvenaud: http://www.cs.toronto.edu/~duvenaud/
    affiliations:
    - University of Toronto
    - University of Toronto
</script>

<title>Bayesian Neural Networks</title>

<dt-article class="centered">
    <link rel="stylesheet" type="text/css" href="assets/widgets.css">
    <!-- <script src="assets/lib/lib.js"></script> -->
    <script src="assets/utils.js"></script>
    <H1>Bayesian Neural Networks</H1>
    <p>
        How do we prevent neural networks from overfitting? We can avoid trying to choose a single best set of weights, and instead average over all posible weights.
    </p>

    <dt-byline></dt-byline>

    <h2>Visualizing Overfitting</h2>
    <p>Current deep learning methods learn one set of weight in a vast weight space, chosen to minimize a loss function.
        Gradient-based optimization lets us tune millions of parameters, but sometimes the set of weights that works best on the training set works poorly on the unseen test set, which we call <i>overfitting.</i>
   </p>

    <p>One way to understand overfitting is that the optimum of the loss function on the training set might be in a different place than the optimum on the test set.
        Below, we can see this happen when fitting the weights of a neural network.
   </p>

    <!-- Regular MLP figure -->
    <figure style="position:relative; width:984px; height:350px;">
        <figcaption id="NN_caption">
            Neural Network
        </figcaption>
        <div id="nn_full" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <button type="button" onclick="mlp.train()">Train</button>
        <button type="button" onclick="mlp.reset()">Reset</button>
        <figcaption id="Overfitcaption" style="position:absolute; width: 420px; height: 10px; left: 540px; top: 340px;">
A three-layer MLP fitting the training set (red dots). Green dots show the test set.
        </figcaption>
    </figure>

    <figure style="position:relative; width:984px; height:330px;">
        <section class="container">
            <div id="nn_loss_train" style="position:relative; float:left; width: 320px; height: 320px;">
                <figcaption id="nn_loss_train_title" style="position:relative; text-align:center;right:10px">
                    Training Loss
                </figcaption>
            </div>
            <div id="nn_loss_valid" style="position:relative; margin-left: 684px; width: 320px; height: 320px;">
                <figcaption id="nn_loss_test_title" style="position:relative; text-align:center;right:10px">
                    Test Loss
                </figcaption>
            </div>
        </section>
        <figcaption id="NNLosscaption" style="position:absolute; width: 152px; height: 90px; left: 416px; top: 120px; margin: 0 auto;">
            The loss surface of the neural network. The training loss (the negative log-likeihood) is plotted on the left, and the test-set loss is plotted on the right.
        </figcaption>
    </figure>

    <p>
        In this example, we've pre-trained all the weights in the neural network except for two weights in the first layer, which we call weight 1 and weight 2.
    </p>

    <h3>Regularization</h3>
    <p>
        One approach to avoiding overfitting is to regularize the weights, or choose a small model.
        This usually helps, but this approach still considers only set of weights when making predictions. But this doesn't have to be the case.
    </p>

    <h2>Bayesian Inference</h2>
    <p>
        Another approach to making predictions would be to considers all possible sets of weights.
        Since not all sets of weights fit the data equally well, we can weight their predictions proportional to how well they fit.
        If we view learning like descending a valley, we want the model to survey the entire landscape, instead of descending the first deep trough it sees.
    </p>

    <p>
        One way to keep track of the relative importance given to each set of weights 
        Bayes' rule gives is a simple and coherent method for assigning measuring the What if we used probability for the objective function instead?
        Then the loss space defines a probability distribution over all the weights.
        This gives us the ability to sample from the space, and the probability of each weight being sampled automatically
        confers its importance.
        We could use Bayes' theorem to express the relationship between the data points and the weights:
    </p>

    <div id="exacttex">$$p(w|x) = \dfrac{p(x|w)p(w)}{p(x)}$$</div>

    <p>Where $p(x|w)$ is called likelihood, $p(w)$ prior, and $p(w|x)$ posterior.</p>

    <p>
        There are many possible strategies to try to avoid overfitting, generally called regularization methods. Instead of choosing the weights that best fit to the training data, these methods try to balance data fit with the complexity of the function being
        learned. With Bayesian neural network, first developed by
        <dt-cite key="neal1995bayesian"></dt-cite> and
        <dt-cite key="graves2011practical"></dt-cite>, which combines the power of a neural network with the flexibility of bayesian methods, we can fit the best set of weights and regularize at the same time.
    </p>

    <h3>What about the prior?</h3>
    <p>
        One difficulty with Bayesian methods is that we're sometimes forced to choose a prior. If we assumed the wrong the prior, the model underperforms. However, the important difference between Bayesian and non-Bayesian methods isn't the prior, it's the fact
        that we make predictions in a way that considers all possibilities and not just one. This is why MAP estimate is <i>not</i> a Bayesian method - despite its seemingly innocent use of Bayes' theorem - since it doesn't infer a distribution
        of the parameters.
    </p>
    <p>
        Sometimes, incorporating a priopr is sold as a benefit, since it lets us incorporate knowledge about our problem into our method. (It also allows us to tweak the inference process, for example, using a standard Gaussian prior that punishes large weights
        by making them less probable would natually regularize weights.)
    </p>
    <p>
        To show that Bayesian methods aren't necessarily about priors, in this example we will use an uninformative uniform prior. (ALIGN THE EQUATION)
        <!-- \\begin{aligned} p(w|x) & = \dfrac{p(x|w)p(w)}{p(w)\int_{w}p(x|w)} \\ & = \dfrac{p(x|w)}{\int_{w}p(x|w)}\\end{aligned} -->
    </p>
    <div>
        \begin{matrix} a & b \\ c & d \end{matrix}
    </div>
    <h2>Two Mindsets</h2>
    <h3>Inference</h3>
    <p>
        The term inference have a dual meaning in the community, in a general sense, it means make predictions about some hidden values, the difference lies in what is the unknown value we care about. On one hand - from people who do predictions for a living
        - we mainly care about the value of $y$ given a particular $x$, so natually we are inferencing $y$ from $x, w$. On the other hand, from the probabilistic graphical model community, the latent states of the models are more important than the data
        points, inference is about discovering the distribution of $w$ from $x, y$. In this sense, <b>inference</b> is more like <b>learning</b>.
    </p>
    <h3>Exact Inference</h3>
    <p>
        Notice that Bayes' theorem gives us the exact probability distribution of $w$ given $x$, so we can just assume a prior, compute the posterior and sample weights from it, right? Yes, from a theoretical perspective this is all you need, a closed form solution
        from which you could sample the perfect distribution of w given the data points x. So why doesn't everyone use exact Bayesian inference all the time? Expand the denominator,
    </p>
    <div id="exacttex">$$p(w|x) = \dfrac{p(x|w)p(w)}{\int_{w}p(x|w)p(w)}$$</div>
    <p>
        Even if we discretize w, computing the integral takes exponential number in the number of weights, so it is not computationally feasible. Second, we have to store how well each set of weights fits the training data, which takes up too much space. Markov
        chain monte carlo blahblah.... converges to the exact posterior.....somethingsomething
    </p>

    <!-- Exact Inference figures -->
    <figure style="position:relative; width:984px; height:330px;">
        <div id="exact_train" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <figcaption id="exact_caption" style="position:relative; width: 420px; height: 10px; left: 540px; top: 20px;">
            Now we integrate out the of weights in proportion to the posterior.
        </figcaption>
    </figure>

    <figure style="position:relative; width:984px; height:400px;">
        <div id="exact_train_contour" style="position:relative; float:left; width: 320px; height: 320px;">
            <figcaption id="exact_train_loss_title" style="position:relative; text-align:center;right:10px">
                Training Loss
            </figcaption>
        </div>
        <div id="progress" style="position:relative; margin-left: 334px; width:650px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <figcaption id="exact_caption" style="position:absolute; width: 470px; height: 60px; left: 510px; top: 310px;">
            The black line shows the validation loss of the average. Observe how validation loss decreases as one sample more and eventually becomes lower than MLE estimate in dark green and the local minimum in dark red.
        </figcaption>
        <button type="button" onclick="sampler.sample_train()">Sample</button>
        <button type="button" onclick="sampler.reset()">Clear</button>
    </figure>
    <p>
        We can see that the posterior puts a lot of mass
    </p>

    <h3>Variational Inference</h3>
    <p>
        Variational inference means, loosely, fitting a nice, tractable distribution (such as a Gaussian, or a million Gaussians) to be as close as possible to the complicated, intractable posterior. Once we find a nice tractable distribution that approximates
        the intractable one, we can use the tractable distribution to make predictions or measure uncertainty within an tractable time complexity.
    </p>
    <p>
        Lets define $p$ as the true distribution and $q$ to be the million-gaussian we use to approximate $p$. We call it a variational distribution. We want $q$ to be close to $p$, but what does it mean for two probability distributions to be close to each other,
        in other words, if we define a loss function that describes the closeness of two distributions, what properties are desired? For starters, if $p = q$, the loss should be 0, also if $p$ and $q$ assign a different probability to the same point,
        we want to punish it by assigning a large loss. Kullback Leibler divergence is such a measure, PUT EQUATION AND HOW ITS ASYMMETRIC HERE.
    </p>


    <!-- KL divergence figure -->
    <figure style="position:relative; width:984px; height:400px;">
        <div id="curve" style="position:relative; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <div id="slider3" style="position:absolute; width:300px; height: 50px; left:20px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Mean μ = 0.0</text>
        </div>
        <div id="slider4" style="position:absolute; width: 300px; height: 50px; left: 280px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Standard Deviation = 1.0</text>
        </div>
        <figcaption id="Gaussiancaption" style="position:absolute; width: 420px; height: 90px; left: 540px; top: 320px;">
            If we were to optimize, we must know the objective. Here, the objective is a measure of differences in two probability distributions. The dark green area represents KL divergence, dark red is reverse KL, orange is Jensen Shannon divergence. Try to minimize
            the areas. Do these measures agree?
        </figcaption>
    </figure>

    <p>
        Using a variational method come with other perks as well: with a clearly defined, continuously differentiable objective, we could use gradient-based methods and optimizers off the shelf.
    </p>

    <!-- Variational Inference Layer -->
    <figure style="position:relative; width:984px; height:330px;">
        <figcaption id="Var_inf_caption">
            Variational Inference
        </figcaption>
        <div id="var_full" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <button type="button" onclick="bnn.train()">Train</button>
        <button type="button" onclick="bnn.reset()">Reset</button>
        <figcaption id="var_caption" style="position:absolute; width: 420px; height: 10px; left: 540px; top: 340px;">
            Now we fit a distribution of weights to the underlying latent distribution.
        </figcaption>
    </figure>

    <figure style="position:relative; width:984px; height:750px;">
        <section class="container">
            <div id="var_loss_train" style="position:relative; float:left; width: 320px; height: 320px;">
                <figcaption id="var_loss_train_title" style="position:relative; text-align:center;right:10px">
                    Training Loss
                </figcaption>
            </div>
            <div id="var_loss_valid" style="position:relative; margin-left: 684px; width: 320px; height: 320px;">
                <figcaption id="var_loss_valid_title" style="position:relative; text-align:center;right:10px">
                    Test Loss
                </figcaption>
            </div>
        </section>
        <figcaption id="var_loss_caption" style="position:absolute; width: 152px; height: 20px; left: 416px; top: 120px; margin: 0 auto;">
            The loss surface for the Variational Net. The training loss is plotted on the left, the validation loss is plotted on the right.
        </figcaption>
        <div id="var_progress" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <button type="button" onclick="bnn.sample()">Sample</button>
        <figcaption id="exact_caption" style="position:absolute; width: 470px; height: 60px; left: 600px; top: 700px;">
            What if you sampled from the learned distribution?
        </figcaption>
    </figure>
    <h3>Expression of Uncertainty</h3>
    <p>Normal neural nets doesn't have a good way of expressing uncertainty. For example, if we fit two neural networks on the following data, we could see that it is possible for them to have similar fit, but predicts drastically differently.</p>

    <figure style="position:relative; width:984px; height:350px;">
        <figcaption id="disagree">
            Two Nets Duking it Out
        </figcaption>
        <div id="dis_full" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <figcaption id="dis_caption" style="position:absolute; width: 420px; height: 10px; left: 540px; top: 330px;">
            Two nets that wants to punch each other in the face.
        </figcaption>
    </figure>

    <p>Some would argue that the network is indeed uncertain about if the datapoints in the middle belongs to a particular class by assigning it a low probability. However, that is not the type of uncertainty we are talking about here, what we really want is for the network to be uncertain of itself.</p>

    <figure style="position:relative; width:984px; height:350px;">
        <figcaption id="disagree">
            A Change in Perspective
        </figcaption>
        <div id="uncertain_mlp" style="position:relative; float:left; width:485px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <div id="uncertain_bnn" style="position:relative; margin-left: 499px; width:485px; height:300px; border: 1px solid rgba(0, 0, 0, 0.1);"></div>
        <button type="button" name="uncertain_train" onclick="uncertainty.train()">Train</button>
        <button type="button" name="uncertain_reset" onclick="uncertainty.reset()">Reset</button>
    </figure>

    <h3>Automatic Differentiation Variational Inference</h3>
    <p>
        The reparameterization trick
        <dt-cite key="kingma2013autoencoding"></dt-cite>
        <dt-cite key="rezende2014stochastic"></dt-cite>

        ADVI
        <dt-cite key="kucukelbir2016automatic"></dt-cite>

        Bayes by backprop
        <dt-cite key="blundell2015weight"></dt-cite>
    </p>

    <H3>Connection to Dropout</H3>
    <p>
        Dropout can be seen as an approximation to stochastic variational inference, where we add weights that can turn off each unit entirely, and integrate out these weights.
        <dt-cite key="kingma2015variational"></dt-cite>
        <dt-cite key="gal2016dropout"></dt-cite>
    </p>

    <H3>Connection to Ensembles</H3>
    <p>
        asdf
    </p>

    <H3>Connection to Gradient Noise</H3>
    <p>
        asdf
    </p>

    <p>
        Our implementation is based on
        <dt-cite key="karpathy2015convnetjs"></dt-cite>
    </p>

    <script src="assets/lib/parameters.js"></script>
    <script src="assets/lib/plotter.js"></script>
    <script src="assets/lib/gaussian_curve.js"></script>
    <script src="assets/lib/contour_plot.js"></script>
    <script src="assets/lib/mlp.js"></script>
    <script src="assets/lib/bnn.js"></script>
    <script src="assets/lib/uncertainty.js"></script>
    <script src="assets/lib/sampler.js"></script>
    <script src="assets/lib/net_lib.js"></script>
    <script src="assets/lib/seedrandom.min.js"></script>
    <script src="assets/iterates.js"></script>
    <script>
        //DIVERGENCES
        var curve = GaussianCurve(0, 1, d3.select("#curve"));
        var sdScaler = d3.scaleLinear().domain([0, 4]).range([0.5, 2.5])

        var sliderc = sliderGen([230, 40])
            .ticks([0, 5, 10, 15, 20])
            .ticktitles(function(d, i) {
                return ["-10", "-5", "0", "5", "10"][i]
            })
            .change(function(i) {
                d3.select("#slider3").selectAll(".figtext").html("Mean μ = " + (getmean() - 10).toPrecision(2))
                curve.update(getmean() - 10, sdScaler(getsd()))
            })
            .startxval(10)
            .cRadius(7)
            .shifty(-12)
            .margins(20, 20)
        var sliderd = sliderGen([230, 40])
            .ticks([0, 1, 2, 3, 4])
            .ticktitles(function(d, i) {
                return ["0.5", "1", "1.5", "2", "2.5"][i]
            })
            .change(function(i) {
                d3.select("#slider4").selectAll(".figtext").html("Standard Deviation = " + sdScaler(getsd()).toPrecision(2))
                curve.update(getmean() - 10, sdScaler(getsd()))
            })
            .cRadius(7)
            .shifty(-12)
            .startxval(1)
            .margins(20, 20)

        var getmean = sliderc(d3.select("#slider3")).xval
        var getsd = sliderd(d3.select("#slider4")).xval
        curve.drawLine();

        // NN on sine
        var mlp = mlp(d3.select("#nn_full"), d3.select("#nn_loss_train"), d3.select("#nn_loss_valid"));
        mlp.plot();

        // exact inference
        var sampler = sampler(d3.select("#exact_train"), d3.select("#exact_train_contour"), d3.select("#progress"));
        sampler.plot();

        // variational inference
        var bnn = bnn(d3.select("#var_full"), d3.select("#var_loss_train"), d3.select("#var_loss_valid"), d3.select("#var_progress"));

        var uncertainty = uncertainty(d3.select("#dis_full"), d3.select("#uncertain_mlp"), d3.select("#uncertain_bnn"))
    </script>
</dt-article>

<dt-appendix>
</dt-appendix>

<script>
    renderMathInElement(
        document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                },
                {
                    left: "\\\\",
                    right: "\\\\",
                    display: true
                },
                {
                    left: "\\",
                    right: "\\",
                    display: false
                },
            ]
        }
    );
</script>

<script type="text/bibliography">
    @inproceedings{graves2011practical, title={Practical variational inference for neural networks}, author={Graves, Alex}, booktitle={Advances in Neural Information Processing Systems}, pages={2348--2356}, year={2011} } @misc{karpathy2015convnetjs, title={ConvNetJS:
    Javascript library for deep learning}, author={Karpathy, A}, year={2015} } @phdthesis{neal1995bayesian, title={Bayesian learning for neural networks}, author={Neal, Radford M}, year={1995}, school={University of Toronto} } @article{kingma2013autoencoding,
    author = {Diederik P. Kingma and Max Welling}, title = {Auto-Encoding Variational Bayes}, journal = {International Conference on Learning Representations}, year = {2014} } @inproceedings{rezende2014stochastic, title={Stochastic Backpropagation and
    Approximate Inference in Deep Generative Models}, author={Rezende, Danilo J and Mohamed, Shakir and Wierstra, Daan}, booktitle={Proceedings of the 31st International Conference on Machine Learning}, pages={1278--1286}, year={2014} } @article{rumelhart1986learning,
    title={Learning representations by back-propagating errors}, author={Rumelhart, David E and Hinton, Geoffrey E}, journal={Nature}, volume={323}, pages={9}, year={1986} } @inproceedings{kingma2015adam, title={{Adam}: A Method for Stochastic Optimization},
    year={2015}, author={Kingma, Diederik and Ba, Jimmy}, booktitle={International Conference on Learning Representations}, } @article{hoffman2013stochastic, title={Stochastic variational inference}, author={Hoffman, Matthew D and Blei, David M and Wang,
    Chong and Paisley, John}, journal={The Journal of Machine Learning Research}, volume={14}, number={1}, pages={1303--1347}, year={2013} } @inproceedings{schulman2015gradient, title={Gradient estimation using stochastic computation graphs}, author={Schulman,
    John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter}, booktitle={Advances in Neural Information Processing Systems}, pages={3528--3536}, year={2015} } @phdthesis{speelpenning1980compiling, title={Compiling Fast Partial Derivatives of Functions
    Given by Algorithms}, author={Speelpenning, Bert}, year={1980}, school={University of Illinois at Urbana-Champaign} } @article{rall1981automatic, title={Automatic differentiation: Techniques and applications}, author={Rall, Louis B}, year={1981},
    publisher={Springer} } @article{robbins1951stochastic, title={A stochastic approximation method}, author={Robbins, Herbert and Monro, Sutton}, journal={The annals of mathematical statistics}, pages={400--407}, year={1951} } @article{kucukelbir2016automatic,
    title={Automatic Differentiation Variational Inference}, author={Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M}, journal={arXiv preprint arXiv:1603.00788}, year={2016} } @article{paisley2012variational,
    title={Variational Bayesian inference with stochastic search}, author={Paisley, John and Blei, David and Jordan, Michael}, journal={arXiv preprint arXiv:1206.6430}, year={2012} } @inproceedings{blundell2015weight, title={Weight Uncertainty in Neural
    Network}, author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan}, booktitle={International Conference on Machine Learning}, pages={1613--1622}, year={2015} } @inproceedings{gal2016dropout, title={Dropout as a Bayesian
    approximation: Representing model uncertainty in deep learning}, author={Gal, Yarin and Ghahramani, Zoubin}, booktitle={international conference on machine learning}, pages={1050--1059}, year={2016} } @inproceedings{kingma2015variational, title={Variational
    dropout and the local reparameterization trick}, author={Kingma, Diederik P and Salimans, Tim and Welling, Max}, booktitle={Advances in Neural Information Processing Systems}, pages={2575--2583}, year={2015} }
</script>
