<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=1080">

<!-- <script src="https://distill.pub/template.v1.js"></script> -->
<script src="assets/lib/template.v1.js"></script>
<script src="assets/lib/d3.v4.min.js"></script>
<script src="assets/lib/d3-contour.v1.min.js"></script>
<script src="assets/lib/d3-scale-chromatic.v1.min.js"></script>
<script src="assets/lib/katex.min.js"></script>
<script src="assets/lib/auto-render.min.js"></script>
<script src="assets/lib/pseudocode.min.js"></script>
<link rel="stylesheet" type="text/css" href="assets/lib/katex.min.css">
<link rel="stylesheet" type="text/css" href="styles.css">
<link rel="stylesheet" type="text/css" href="assets/widgets.css">
<link rel="stylesheet" type="text/css" href="assets/lib/pseudocode.min.css">




<script type="text/front-matter">
    title: "Bayesian Neural Networks"
    description: "By combining neural networks with Bayesian inference, we can learn a probability distribution over possbile models. This simple modification to standard neural network tools mitigates overfitting, enables learning from small datasets, and gives us unceratinty estimates."
    authors:
    - Jerry Qinghui Yu: http://www.cs.toronto.edu/~jerry/
    - Elliot Creager: http://www.cs.toronto.edu/~creager/
    - David Duvenaud: http://www.cs.toronto.edu/~duvenaud/
    affiliations:
    - University of Toronto
    - University of Toronto, Vector Institute
    - University of Toronto, Vector Institute
</script>

<title>Bayesian Neural Networks</title>

<dt-article id="article" class="centered">
    <link rel="stylesheet" type="text/css" href="assets/widgets.css">
    <script src="assets/utils.js"></script>
    <!-- <script src="assets/lib/lib.js"></script> -->
    <figure style="width:100%; height:400px;">
            <div id="full_bnn" class='.l-screen' style="width:100%; height:400px;"></div>
    </figure>

    <H1>Bayesian Neural Networks</H1>
    <p>
    Bayesian inference allows us to learn a probability distribution over possible neural networks.
    This simple modification to standard neural network tools mitigates overfitting, enables learning from small datasets, and tells us how uncertain our predictions are.
    </p>

    <figure>
        <div id="bnn_graph" style="position:relative; width:650px; height:200px;"></div>
        <button type="button" onclick="full_bnn.train()">Train</button>
        <button type="button" onclick="full_bnn.reset()">Reset</button>
    </figure>

    <dt-byline></dt-byline>

    <h2>What's wrong with neural networks?</h2>
    <p>
        You may have heard deep neural networks described as <i>powerful function approximators</i>.
        Their power is due to the extreme flexibility of having many model parameters (the weights and biases) whose values can be learned from data via gradient-based optimization.
        Because they are good at approximating functions (input-output relationships) when lots of data are available, neural networks are well-suited to artificial intelligence tasks like speech recognition and image classification.
    </p>

    <p>
        But the extreme flexibility of neural networks has a downside: they are particularly vulnerable to <i>overfitting</i>.
        Overfitting happens when the learning algorithm does such a good job of tuning the model parameters for performance on the training set&mdash;by optimizing its <i>objective function</i>&mdash;that the performance on new examples suffers.
        Deep neural networks have a ton of parameters (typically millions in modern models), which essentially guarantees eventual overfitting because the learning algorithm can always do just a little bit better on the training set by tweaking some of the many knobs available to it.
        The flexibility of neural networks during training time actually makes them brittle at test time.
        This might sound surprising at first, but let's look at the training procedure both mathematically and graphically (for a toy problem) to build some intuition around why deep neural networks overfit.
    </p>

    <!-- Regular MLP objective surfaces -->
    <figure style="position:relative; width:984px;">
        <div class="container">
            <div style="display: table; height: 100%">
                <div class='table-cell-wrap'>
                    <figcaption id="nn_loss_train_title" class='little_caption'>
                        Training likelihood $\mathcal{L}_{\text{train}}(w_1, w_2)$
                    </figcaption>
                    <div id="nn_loss_train" class='contour'> </div>
                </div>
                <div class='table-cell-wrap'>
                    <figcaption id="NNLosscaption" style="position: relative; width: 250px; left: 30px; right: 30px; top: 10px;">
                        The neural network objective $\mathcal{L}$ is a function of both the weights and the dataset.
                        Here we show $\mathcal{L}_{\text{train}}$ and $\mathcal{L}_{\text{test}}$ as a function of only two of the neuron weights, with the remaining weights fixed to pre-trained values.
                        Bluer is better.
                        Use your mouse to change the values of the weights for these neurons.
                        Notice how they affect both the training and test objectives (left, right) and the network predictions changes below, where red are training data and green are test data.
                    </figcaption>
                </div>
                <div class="table-cell-wrap">
                    <figcaption id="nn_loss_test_title" class='little_caption'>
                        Test likelihood $\mathcal{L}_{\text{train}}(w_1, w_2)$
                    </figcaption>
                    <div id="nn_loss_valid" class='contour'> </div>
                </div>
            </div>
        </div>

        <div class="container" style="height: 250px; top: 40px;">
            <div style="display: table; height: 100%">
                <div class='table-cell-wrap'>
                    <figcaption id="nn_full_title" class='little_caption'>
                        Prediction function $\hat y_w(x)$. Red dots are training data, green are test.
                    </figcaption>
                    <div id="nn_full" class='bordered' style="width:440px; height: 200px;"></div>
                </div>
                <div class='table-cell-wrap'>
                    <figcaption id="nn_graph_title" class='little_caption'>
                        Neural net architecture
                        <!-- Notice how the choice of architecture affects the contours of the $\mathcal{L}_{\text{train}}$ and $\mathcal{L}_{\text{test}}$, and that simpler architectures make the two functions more similar. -->
                    </figcaption>
                    <div id="nn_graph" style="width:440px; height: 200px;"></div>
                </div>
                <div class='table-cell-wrap' style="width: 100px;">
                    <form onclick="mlp.update()" style="top: 50px;">
                        <input type="radio" name="net_type" value="Deep" checked> Deep<br>
                        <input type="radio" name="net_type" value="Shallow"> Shallow<br>
                        <input type="radio" name="net_type" value="Linear"> Linear<br>
                    </form>
                    <button type="button" onclick="mlp.train()">Train</button>
                    <button type="button" onclick="mlp.reset()">Reset</button>
                </div>
            </div>
        </div>
    </figure>



    <p>
        First, some notation: let's call inputs $x$ and outputs $y$ and the training set $\mathcal{D}_{\text{train}}$, which is a finite collection of intput-output pairs.
        Similarly we have a test set $\mathcal{D}_{\text{test}}$ of <i>different</i> input-output pairs.
        Then neural network training corresponds to the following optimization problem:
    </p>
    <p>
        $\underset{w}{\text{maximize}} \quad \mathcal{L}_{\text{train}}(w)$
    </p>
    <p>
        where $\mathcal{L}_{\text{train}}$, the <i>expected log likelihood</i> of the training data, is a function of the weights $w$, and is defined as
    </p>
    <p>
        $\mathcal{L}_{\text{train}}(w) \coloneqq \mathbb{E}_{x, y \sim \mathcal{D}_{\text{train}}} \left[ \log p(\hat y(x) = y|, w) \right]$
        .
    </p>
    <p>
        Here $\log p(\hat y(x) = y| w)$ represents the log likelihood<dt-fn>
            Adding weight decay to this objective is easy, we simply add a prior on $w$ to the log likelihood, expressed as $\log p(w) = \lambda ||w||_2^2$ (up to an additive constant).
            </dt-fn>
        of a particular output $y$ being predicted given the input $x$, which we want to be high on average across all of the training examples<dt-fn>
        We could equivalently write down the optimization problem as minimizing an expected loss instead of maximizing an expected log likelihood.
        In classification, using cross entropy loss is equivalent to modeling output predictions according to a Categorical (i.e., multinomial) distribution
    </dt-fn>.
        Since we'll use $p(\hat y(x) = y|x)$ often, let's name it the <i>single network likelihood</i>; we might write this likelihood as $p(\hat y|w)$ for short, when the context is clear.
    </p>
    <p>
        During training we optimize $\mathcal{L}_{\text{train}}(w)$ with respect to $w$, but we <i>actually</i> care about performing well on the test data, as measured by $\mathcal{L}_{\text{test}}(w)$.
        In the demo above, we plot these functions side-by-side as a function of two weights<dt-fn>
        In this example, we've pre-trained all the weights in the neural network except for two weights in the first layer, which we call $w_1$ and $w_2$.
    </dt-fn>.
        Notice that the optimial weights $w^* = \underset{w}{\text{arg max}}\mathcal{L}_{\text{train}}(w) $ yield a suboptimal test loss $\mathcal{L}_{\text{test}}(w^*)$.
        This indicates overfitting, which manifests as the neural net generalizing poorly: it makes predictions $\hat y(x)$ that hug closely to the training data at the expense of deviating from the test data.

        Scaling up to networks with millions of weights amplifies the severity of overfitting, since $\mathcal{L}_{\text{train}}(w)$ and $\mathcal{L}_{\text{test}}(w)$ tend to be much more dissimilar in high dimensions.
        Indeed, one key insight from deep learning is that the more capacity<dt-fn>
        Very often "capacity" is shorthand for "depth"
    </dt-fn>
        a model has, the better it is at finding local optima on the training loss, thus the more it will eventually overfit.
        Our demo illustrates the contrapositive: if we restrict the network to have only one hidden layer ("shallow") or no activations ("linear") we see that $\mathcal{L}_{\text{train}}$ looks similar to $\mathcal{L}_{\text{test}}$, so there's little danger of overfitting.
    </p>

    <h2>Bayes to the rescue</h2>
    <p>
        The problem of overfitting is certainly not unique to neural networks.
        But because the flexibility of neural networks makes them particularly susceptible, researchers and practitioners have come up with many extensions to the standard learning algorithm (early stopping, weight decay, and dropout, just to name a few) to reduce overfitting<dt-cite key="hinton2012improving"></dt-cite>.
    </p>

    <p>
        This tutorial focuses on <i>Bayesian inference</i>, a powerful framework that not only helps with overfitting, but also tells us how uncertain our model is about its parameters.
        Before we used the training data $\mathcal{D}_{\text{train}}$ plus a gradient-based optimizer to tune the weights $w$ in order to maximize $\mathcal{L}_{\text{train}}(w)$.
        In Bayesian inference, instead of learning the parameter values, we seek to compute $p(w | \mathcal{D}_{\text{train}})$, the conditional distribution of the weights given the training data.
        $p(w|\mathcal{D}_{\text{train}})$ is called the <i>posterior distribution</i>, or often the <i>posterior</i> for short.
    </p>

    <h3>Exact Bayesian inference</h3>
    <p>
        Exact Bayesian inference tells us how to compute the posterior.
        It's API is called Bayes' rule, which says
    </p>
    <p>
        $p(w | \mathcal{D}) = \dfrac{p(\mathcal{D}|w)p(w)}{p(\mathcal{D})} = \dfrac{p(\mathcal{D}|w)p(w)}{\int_{w'} p(\mathcal{D}|w')p(w') dw'}$
        .
    </p>
    <p>
        It's call signature requires two input distributions, the <i>prior</i> $p(w)$, and the <i>likelihood</i> $p(\mathcal{D} | w)$, and returns the posterior $p(w | \mathcal{D})$.
        While the posterior distribution is easily expressed, it is tyipcally expensive to compute due to the pesky integral over all possible values of $w$.
        For most neural network we can't evaluate this integral analytically.
        We could instead approximate it numerically, but this will only be practical for small neural networks, since $w$ represents all the weights and biases, so it becomes very high dimensional for deep networks.
    </p>
    <p>
        So we will need to address this computational issue, which we do in the next section.
        In the meantime, let's consider another upside of using the posterior distribution over weights $p(w|\mathcal{D})$ instead of the estimate $w^*$ from standard neural network training.
        In particular, knowing the posterior allows us to do probabilistic prediction by expressing a distribution over predicted output $\hat y$ as a function of new input $x$,
    </p>
    <p>
    $p(\hat y(x)| \mathcal{D}) = \int_{w} p(\hat y(x)| w) p(w | \mathcal{D}) dw = \mathbb{E}_{w \sim p(w|\mathcal{D})}[p(\hat y(x)|w)]$, <!-- why not p(w| \mathcal{D}, x) here...-->
    </p>
    <p>
        which we call the <i>predictive distribution</i>.
        Notice that we can express this distribution as the expectation of the single network likelihood under the posterior $p(w|\mathcal{D})$.
        This yields a nice interpretation of the predictive distribution as an <i>infinite emsemble</i> of networks, with each network's contribution to the overall prediction weigted by the posterior likelihood of its weights given the training data<dt-cite key="blundell2015weight"></dt-cite>.
        Also, it implies that we can approximate this infinite ensemble using a finite number of Monte Carlo samples from the posterior.
        Approximating the predictive distribution with only a single Monte Carlo sample is equivalent to using a single neural network $\hat y(x)$ with weights $w$ chosen at random from $p(w|\mathcal{D})$; in a slight abuse of terminology, we can think of this process as <i>sampling networks</i> from the posterior.
    </p>
    <p>
        The demo below illustrates the predictive distribution as well as its approximation using Monte Carlo samples of networks from the posterior.
        Remember that exact inference is only possible for small networks; in this case we consider two freely variable weights in a three layer network, with the remaining weights held fixed.
   </p>

     <!-- Exact Inference figures -->
    <figure style="position:relative; width:984px; height:310px;">
        <div id="exact_train" class='bordered' style="position:relative; width:984px; height:300px;"></div>
        <figcaption id="exact_caption" style="position:relative; width: 420px; height: 10px; left: 540px; top: 10px;">
            The predictive distribution $p(\hat y(x)|\mathcal{D}_{\text{train}})$ is shown in red.
            Press the 'sample' below to draw sampled networks $\hat y_w(x)$ with $w \sim p(w|\mathcal{D}_{\text{train}})$.
        </figcaption>
    </figure>

    <figure style="position:relative; width:984px; height:400px;">
        <div id="exact_train_contour" style="position:relative; float:left; width: 320px; height: 320px;">
            <figcaption id="exact_train_loss_title" class='little_caption'>
                Training Loss
            </figcaption>
        </div>
        <div>
            <figcaption id="progress_label" class='little_caption'>
                Average Test Loss
            </figcaption>
            <div id="progress" class='bordered' style="position:relative; margin-left: 334px; width:650px; height:280px;">

            </div>
        </div>
        <figcaption id="exact_caption" style="position:absolute; width: 420px; height: 60px; left: 560px; top: 310px;">
            The black line shows the validation loss of the average.
            Observe how validation loss decreases as one sample more and eventually becomes lower than MLE estimate in dark green.
        </figcaption>
        <button type="button" onclick="exact_inference_view.sample_train()">Sample</button>
        <button type="button" onclick="exact_inference_view.reset()">Clear</button>
    </figure>

   <!- SAY SOMETHING ABOUT THE INTERPRETATION OF THE PRIOR AND LIKELIHOOD HERE, AND ADD SOME ANALYSIS TO THE DEMO->
   </p>

   <h3>Variational inference</h3>
    <p>
        We can scale up inference by settling for an approximate solution via <i>variational inference</i>.
        The API requires one additional argument, $q(\theta)$, called the <i>variational distribution</i>, and returns the <i>approximate posterior</i> $q^*(\theta)$ according to
        $$q^*(\theta) = \texttt{argmax} E_{q(\theta)} [ p(x|\theta) ] - D_{KL} [q(\theta)||p(\theta)].$$
        The solution is a good one when the approximate posterior $q(\theta)$ is close to the true posterior $p(\theta|x)$.
        We will use gradient-based optimization to solve the $\texttt{argmax}$ optimization, the same algorithm we used before to train our neural network.
   </p>

   <!-- KL divergence figure -->
    <figure style="position:relative; width:984px; height:400px;">
        <div id="curve" class='bordered' style="position:relative; float:left; width:834px; height:300px;"></div>
        <form style="position:relative; margin-left: 854px;" onclick="divergence_curve.update(getmean() - 6, sdScaler(getsd()))">
            <input type="radio" name="divergence_type" value="KL" checked> KL<br>
            <input type="radio" name="divergence_type" value="reverse KL"> reverse KL<br>
            <input type="radio" name="divergence_type" value="JS"> JS
        </form>
        <div id="slider3" style="position:absolute; width:300px; height: 50px; left:20px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Mean μ = 0.0</text>
        </div>
        <div id="slider4" style="position:absolute; width: 300px; height: 50px; left: 280px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Standard Deviation = 1.0</text>
        </div>
        <figcaption id="Gaussiancaption" style="position:absolute; width: 420px; height: 90px; left: 540px; top: 320px;">
            If we were to optimize, we must know the objective. Here, the objective is a measure of differences in two probability distributions. The dark green area represents KL divergence, dark red is reverse KL, orange is Jensen Shannon divergence. Try to minimize
            the areas. Do these measures agree?
        </figcaption>
    </figure>


    <p style="color:red;">
    TODO: We should say something about the role of the KL-divergence here and reference the figure.
    It would be nice to figure out how to put a legend in the KL interactive figure to clarify things.
    </p>


    <h2>Optimizing with gradients</h2>
    <p style="color:red;">
    TODO: The purpose of this section is to discuss SGD vs. SVI in more detail, and provide the algorithms side-by-side.
    We should also cite relevant papers, e.g.,
    </p>

   <figure style="position:relative; width:800px; height:200px;">
       <div class="container" style="width: 800px;">
           <div id="svi-algo-box-left" style="display: table-cell;"></div>
           <div id="svi-algo-box-right" style="display: table-cell;"></div>
       </div>
   </figure>

    <pre id="hello-world-code">
    \begin{algorithmic}
    \PROCEDURE{SGD}{$x, y, w$}
        \WHILE {training not converged}
            \STATE $g = \text{BACKPROP}(x, y, w)$
            \STATE $w = w + \alpha g$
        \ENDWHILE
        \ENDPROCEDURE
    \end{algorithmic}
    </pre>

    <pre id="hello-world-code2">
    \begin{algorithmic}
    \PROCEDURE{SVI}{$x, y, w$}
        \WHILE {training not converged}
            \STATE ${\color{blue} \epsilon \sim \mathcal{N}(0, I)}$
            \STATE $g = \text{BACKPROP}(x, y, {\color{blue} w+\epsilon\sigma})$
            \STATE $w = w + \alpha g$
            \STATE ${\color{blue}\sigma = \sigma + \alpha\epsilon g}$
        \ENDWHILE
        \ENDPROCEDURE
    \end{algorithmic}
    </pre>

    <p>
        Using a variational method come with other perks as well: with a clearly defined, continuously differentiable objective, we could use gradient-based methods and optimizers off the shelf.
    </p>

    <!-- Variational Inference Layer -->
    <figure style="position:relative; width:984px; height:1075px;">
        <figcaption id="Var_inf_caption">
            Variational Inference
        </figcaption>
        <figcaption id="var_caption">
            Now we fit a distribution of weights to the underlying latent distribution.
        </figcaption>
        <div id="var_full" class='bordered' style="position:relative; width:984px; height:300px;"></div>
        <button type="button" onclick="bnn.train()">Train</button>
        <button type="button" onclick="bnn.sample()">Sample</button>
        <button type="button" onclick="bnn.reset()">Reset</button>

        <figcaption id="exact_caption" style="position:relative; width: 470px; height: 10px; left:500px">
            What if you sampled from the learned distribution?
        </figcaption>
        <div class="container" style="margin-top: 20px;">
            <div id="var_progress" class='bordered' style="display: table-cell; width:364px; height:200px;"></div>
            <div id="var_graph" style="display: table-cell; width:600px; height:200px;"></div>
        </div>

        <div class='container'>
            <div style="display: table; height: 100%">
                <div class='table-cell-wrap'>
                    <figcaption id="var_loss_train_title" class='little_caption'>
                        Training Loss
                    </figcaption>
                    <div id="var_loss_train" class='contour'> </div>
                </div>
                <div class='table-cell-wrap'>
                    <figcaption id="var_loss_caption" style="position: relative; width: 150px; left: 75px; right: 75px; top: 100px;">
                        The loss surface for the Variational Net. The training loss is plotted on the left, the validation loss is plotted on the right.
                    </figcaption>
                </div>
                <div class='table-cell-wrap'>
                    <figcaption id="var_loss_valid_title" class='little_caption'>
                        Test Loss
                    </figcaption>
                    <div id="var_loss_valid" class='contour'> </div>
                </div>
            </div>
        </div>
    </figure>
    <h3>Modeling Uncertainty</h3>
    <p style="color:red;">
    TODO: discuss the uncercatinty estimates you get for free by modeling the posterior.
    </p>
    <!-- VARIANCE FIGURE
        <figure style="position:relative; width:984px; height:350px;">
        <figcaption id="disagree">
            A Change in Perspective
        </figcaption>
        <div id="uncertain_mlp" style="position:relative; float:left; width:485px; height:300px; bottom: 10px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <div id="uncertain_bnn" style="position:relative; margin-left: 499px; width:485px; height:300px; bottom: 10px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <button type="button" name="uncertain_train" onclick="uncertainty.train()">Train</button>
        <button type="button" name="uncertain_reset" onclick="uncertainty.reset()">Reset</button>
    </figure> -->

    <!--
        HERE ARE SOME IDEAS FOR EXTRA STUFF TO TALK ABOUT, SPACE PERMITTING
    <h3>Automatic Differentiation Variational Inference</h3>
    <p>
        The reparameterization trick
        <dt-cite key="kingma2013autoencoding"></dt-cite>
        <dt-cite key="rezende2014stochastic"></dt-cite>

        ADVI
        <dt-cite key="kucukelbir2016automatic"></dt-cite>

        Bayes by backprop
        <dt-cite key="blundell2015weight"></dt-cite>
    </p>

    <H3>Connection to Dropout</H3>
    <p>
        Dropout can be seen as an approximation to stochastic variational inference, where we add weights that can turn off each unit entirely, and integrate out these weights.
        <dt-cite key="kingma2015variational"></dt-cite>
        <dt-cite key="gal2016dropout"></dt-cite>
    </p>

    <H3>Connection to Ensembles</H3>
    <p>
        asdf
    </p>

    <H3>Connection to Gradient Noise</H3>
    <p>
        asdf
    </p>
    -->
    <p>
        <!- ELLIOT Q: CAN WE FORMAT THIS LIKE A \citet IN LATEX? ->
        Our implementation is based on Karpathy 2015 <dt-cite key="karpathy2015convnetjs"></dt-cite>.
    </p>

    <script src="assets/lib/parameters.js"></script>
    <script src="assets/lib/plotter.js"></script>
    <script src="assets/lib/divergence.js"></script>
    <script src="assets/lib/contour_plot.js"></script>
    <script src="assets/lib/mlp.js"></script>
    <script src="assets/lib/bnn.js"></script>
    <script src="assets/lib/full_bnn.js"></script>
    <script src="assets/lib/exact_inference.js"></script>
    <script src="assets/lib/net_lib.js"></script>
    <script src="assets/lib/seedrandom.min.js"></script>
    <script src="assets/iterates.js"></script>
    <script>
        // NN on sine
        var mlp = mlp(d3.select("#nn_full"), d3.select("#nn_loss_train"), d3.select("#nn_loss_valid"), d3.select('#nn_graph'));
        mlp.plot();

        // exact inference
        var exact_inference_view = exact_inference_view(d3.select("#exact_train"), d3.select("#exact_train_contour"), d3.select("#progress"));
        exact_inference_view.plot();

        //DIVERGENCES
        var divergence_curve = divergence(d3.select("#curve"), 0, 1);
        var sdScaler = d3.scaleLinear().domain([0, 4]).range([0.5, 2.5])

        var sliderc = sliderGen([230, 40])
            .ticks([0, 3, 6, 9, 12])
            .ticktitles(function(d, i) {
                return ["-6", "-3", "0", "3", "6"][i]
            })
            .change(function(i) {
                d3.select("#slider3").selectAll(".figtext").html("Mean μ = " + (getmean() - 6).toPrecision(2))
                divergence_curve.update(getmean() - 6, sdScaler(getsd()))
            })
            .startxval(6)
            .cRadius(7)
            .shifty(-12)
            .margins(20, 20)
        var sliderd = sliderGen([230, 40])
            .ticks([0, 1, 2, 3, 4])
            .ticktitles(function(d, i) {
                return ["0.5", "1", "1.5", "2", "2.5"][i]
            })
            .change(function(i) {
                d3.select("#slider4").selectAll(".figtext").html("Standard Deviation = " + sdScaler(getsd()).toPrecision(2))
                divergence_curve.update(getmean() - 6, sdScaler(getsd()))
            })
            .cRadius(7)
            .shifty(-12)
            .startxval(1)
            .margins(20, 20)

        var getmean = sliderc(d3.select("#slider3")).xval
        var getsd = sliderd(d3.select("#slider4")).xval
        divergence_curve.draw_line();

        // variational inference
        var bnn = bnn(d3.select("#var_full"), d3.select("#var_loss_train"), d3.select("#var_loss_valid"), d3.select("#var_progress"), d3.select("#var_graph"));

        // variational inference
        var full_bnn = full_bnn_view(d3.select("#full_bnn"), d3.select("#bnn_graph"));
        // full_bnn.train();

        // SGD algo box
       var code = document.getElementById("hello-world-code").textContent;
       var code2 = document.getElementById("hello-world-code2").textContent;
       var parent_left = document.getElementById("svi-algo-box-left");
       var parent_right = document.getElementById("svi-algo-box-right");
       var options = {
            lineNumber: true
        };
        pseudocode.render(code, parent_left, options);
        pseudocode.render(code2, parent_right, options);
    </script>
</dt-article>

<dt-appendix>
  <h3>Acknowledgments</h3>
  <p style="color:red;">
    TODO: Write down our acknowledgements.
  </p>

  <h3>Author contribution</h3>

  <p style="color:red;">
    TODO: List the author contributions.
  </p>
</dt-appendix>

<script>
    renderMathInElement(
        document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                },
                {
                    left: "\\\\",
                    right: "\\\\",
                    display: true
                },
                {
                    left: "\\",
                    right: "\\",
                    display: false
                },
            ]
        }
    );
</script>

<script type="text/bibliography">
@inproceedings{blundell2015weight, title={Weight Uncertainty in Neural Network}, author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan}, booktitle={International Conference on Machine Learning}, pages={1613--1622}, year={2015}, url={https://arxiv.org/abs/1505.05424}}
    @inproceedings{gal2016dropout, title={Dropout as a Bayesian approximation: Representing model uncertainty in deep learning}, author={Gal, Yarin and Ghahramani, Zoubin}, booktitle={international conference on machine learning}, pages={1050--1059}, year={2016}}
    @inproceedings{graves2011practical, title={Practical variational inference for neural networks}, author={Graves, Alex}, booktitle={Advances in Neural Information Processing Systems}, pages={2348--2356}, year={2011} }
    @article{hinton2012improving, title={Improving neural networks by preventing co-adaptation of feature detectors}, author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R}, journal={arXiv preprint arXiv:1207.0580}, year={2012}, url={https://arxiv.org/abs/1207.0580} }
    @article{hoffman2013stochastic, title={Stochastic variational inference}, author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John}, journal={The Journal of Machine Learning Research}, volume={14}, number={1}, pages={1303--1347}, year={2013} }
    @misc{karpathy2015convnetjs, title={ConvNetJS: Javascript library for deep learning}, author={Karpathy, A}, year={2015} }
    @article{kingma2013autoencoding, author = {Diederik P. Kingma and Max Welling}, title = {Auto-Encoding Variational Bayes}, journal = {International Conference on Learning Representations}, year = {2014} }
    @inproceedings{kingma2015adam, title={{Adam}: A Method for Stochastic Optimization}, year={2015}, author={Kingma, Diederik and Ba, Jimmy}, booktitle={International Conference on Learning Representations}, }
    @inproceedings{kingma2015variational, title={Variational dropout and the local reparameterization trick}, author={Kingma, Diederik P and Salimans, Tim and Welling, Max}, booktitle={Advances in Neural Information Processing Systems}, pages={2575--2583}, year={2015} }
    @article{kucukelbir2016automatic, title={Automatic Differentiation Variational Inference}, author={Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M}, journal={arXiv preprint arXiv:1603.00788}, year={2016} }
    @phdthesis{neal1995bayesian, title={Bayesian learning for neural networks}, author={Neal, Radford M}, year={1995}, school={University of Toronto} }
    @article{paisley2012variational, title={Variational Bayesian inference with stochastic search}, author={Paisley, John and Blei, David and Jordan, Michael}, journal={arXiv preprint arXiv:1206.6430}, year={2012} }
    @article{rall1981automatic, title={Automatic differentiation: Techniques and applications}, author={Rall, Louis B}, year={1981}, publisher={Springer} }
    @inproceedings{rezende2014stochastic, title={Stochastic Backpropagation and Approximate Inference in Deep Generative Models}, author={Rezende, Danilo J and Mohamed, Shakir and Wierstra, Daan}, booktitle={Proceedings of the 31st International Conference on Machine Learning}, pages={1278--1286}, year={2014} }
    @article{robbins1951stochastic, title={A stochastic approximation method}, author={Robbins, Herbert and Monro, Sutton}, journal={The annals of mathematical statistics}, pages={400--407}, year={1951} }
    @article{rumelhart1986learning, title={Learning representations by back-propagating errors}, author={Rumelhart, David E and Hinton, Geoffrey E}, journal={Nature}, volume={323}, pages={9}, year={1986} }
    @inproceedings{schulman2015gradient, title={Gradient estimation using stochastic computation graphs}, author={Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter}, booktitle={Advances in Neural Information Processing Systems}, pages={3528--3536}, year={2015} }
    @phdthesis{speelpenning1980compiling, title={Compiling Fast Partial Derivatives of Functions Given by Algorithms}, author={Speelpenning, Bert}, year={1980}, school={University of Illinois at Urbana-Champaign} }
</script>
