<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=1080">

<!-- <script src="https://distill.pub/template.v1.js"></script> -->
<script src="assets/lib/template.v1.js"></script>
<script src="assets/lib/d3.v4.min.js"></script>
<script src="assets/lib/d3-contour.v1.min.js"></script>
<script src="assets/lib/d3-scale-chromatic.v1.min.js"></script>
<script src="assets/lib/katex.min.js"></script>
<script src="assets/lib/auto-render.min.js"></script>
<script src="assets/lib/pseudocode.min.js"></script>
<link rel="stylesheet" type="text/css" href="assets/lib/katex.min.css">
<link rel="stylesheet" type="text/css" href="styles.css">
<link rel="stylesheet" type="text/css" href="assets/widgets.css">
<link rel="stylesheet" type="text/css" href="assets/lib/pseudocode.min.css">

<script type="text/front-matter">
    title: "Bayesian Neural Networks"
    description: "By combining neural networks with Bayesian inference, we can learn a probability distribution over possbile models. This simple modification to standard neural network tools mitigates overfitting, enables learning from small datasets, and gives us unceratinty estimates."
    authors:
    - Jerry Qinghui Yu: http://www.cs.toronto.edu/~jerry/
    - Elliot Creager: http://www.cs.toronto.edu/~creager/
    - David Duvenaud: http://www.cs.toronto.edu/~duvenaud/
    affiliations:
    - University of Toronto
    - University of Toronto
    - University of Toronto
</script>

<title>Bayesian Neural Networks</title>

<dt-article id="article" class="centered">
    <link rel="stylesheet" type="text/css" href="assets/widgets.css">
    <script src="assets/utils.js"></script>
    <!-- <script src="assets/lib/lib.js"></script> -->
    <figure style="width:2480px; height:200px;">
            <div id="full_bnn"></div>
    </figure>

    <H1>Bayesian Neural Networks</H1>
    <p>
    Bayesian inference allows us to learn a probability distribution over possible neural networks.
    This simple modification to standard neural network tools mitigates overfitting, enables learning from small datasets, and tells us how uncertain our predictions are.
    </p>

    <figure>
        <div id="bnn_graph" style="position:relative; width:650px; height:200px;"></div>
        <button type="button" onclick="full_bnn.train()">Train</button>
        <button type="button" onclick="full_bnn.reset()">Reset</button>
    </figure>

    <dt-byline></dt-byline>

    <h2>What's wrong with neural networks?</h2>
    <p>
        You may have heard deep neural networks described as <i>powerful function approximators</i>.
        Their power is due to the extreme flexibility of having many model parameters (the weights and biases) whose values can be learned from data via gradient-based optimization.
        Because they are good at approximating functions (input-output relationships) when data are available, neural networks are well-suited to artificial intelligence tasks like speech recognition and image classification.
    </p>

    <p>
        But the extreme flexibility of neural networks has a downside: they are particularly vulnerable to <i>overfitting</i>.
        Overfitting happens when the learning algorithm does such a good job of tuning the model parameters for performance on the training set&mdash;by minimizing its <i>loss function</i>&mdash;that the performance on new examples suffers.
        Deep neural networks have a ton of parameters (typically millions in modern models), which essentially guarantees eventual overfitting because the learning algorithm can always do just a little bit better on the training set by tweaking some of the many knobs available to it.
        Perhaps surprisingly, the flexibility of neural networks during training time actually makes them brittle during test time.
    </p>

    <!-- Regular MLP figure -->
    <figure style="position:relative; width:1100px; height:200px;">
        <div id="nn_graph" style="position:relative; float:left; width:650px; height:200px;"></div>
        <form style="position:relative; margin-left: 684px; width:150px;" onclick="mlp.update()">
            <input type="radio" name="net_type" value="Deep" checked> Deep<br>
            <input type="radio" name="net_type" value="Shallow"> Shallow<br>
            <input type="radio" name="net_type" value="Linear"> Linear<br>
        </form>
        <button type="button" onclick="mlp.train()">Train</button>
        <button type="button" onclick="mlp.reset()">Reset</button>
        <figcaption id="Overfitcaption" style="position:relative; width: 450px; height: 10px; top: 20px; margin-left: 650px;">
            Neural Networks are function approximators. Here, different models fitting the training set (red dots). Green dots show the test set.
        </figcaption>
    </figure>

    <div id="nn_full" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>

    <figure style="position:relative; width:984px; height:330px;">
        <div class="container">
            <div id="nn_loss_train" style="display: table-cell; width: 320px; height: 320px;">
                <figcaption id="nn_loss_train_title" style="position:relative; text-align:center;right:10px">
                    Training Loss
                </figcaption>
            </div>
            <div style="display: table-cell; width: 320px; height: 300px;">
                <figcaption id="NNLosscaption" style="position: relative; width: 150px; left: 75px; right: 75px; top: 100px;">
                    The loss surface of the neural network. The training loss (the negative log-likeihood) is plotted on the left, and the test-set loss is plotted on the right.
                </figcaption>
            </div>
            <div id="nn_loss_valid" style="display: table-cell; width: 320px; height: 320px; left: 75px;">
                <figcaption id="nn_loss_test_title" style="position:relative; text-align:center;right:10px">
                    Test Loss
                </figcaption>
            </div>
        </div>
    </figure>


    <p>
        With toy examples it's often easy to notice when the neural net has overfit.
        As training proceeds, the learned function warps drastically as it increases its proximity to the training examples.
        This happens because the learning algorithm is minimizing the value of the loss function, which is a smooth function of the parameters.
        But the loss function also depends on the data, and its surface will have different contours depending on whether we evaluate it using the training data or test data; a local optimum in the training loss surface might not be optimal in the test loss surface; if the two surfaces look really different there is a danger of overfitting.
    </p>

    <p>
        One key insight from deep learning is that the more capacity (read: depth) a model has, the better it is at finding local optima on the training loss, thus the more it will eventually overfit.
        You can play with the above demo to convince yourself of this.
        In this example, we've pre-trained all the weights in the neural network except for two weights in the first layer, which we call weight 1 and weight 2.
    </p>

    <h2>Bayes to the rescue</h2>
    <p>
        Any machine learning model can potentially suffer from overfitting.
        Because neural networks are particularly susceptible, researchers and practitioners have come up with many extensions to the standard learning algorithm (early stopping, weight decay, and dropout, just to name a few) to reduce overfitting.
    </p>

    <p>
        This tutorial focuses on <i>Bayesian inference</i>, a powerful framework that not only helps with overfitting, but also tells us how uncertain our model is about its parameters.
        Before we used the training data $x$ plus a gradient-based optimizer to tune the values of the network parameters $\theta$ by minimizing the loss $\ell(\theta, x)$.
        In Bayesian inference, instead of learning the parameter values, we compute $p(\theta|x)$ a conditional distribution over the parameter values given the training data.
        $p(\theta|x)$ is called the <i>posterior distribution</i>, or simply the <i>posterior</i>.
    </p>

    <h3>Exact Bayesian inference</h3>
    <p>
        Exact Bayesian inference tells us how to compute the posterior; it's API is called Bayes' rule, which says
        $p(\theta|x) = \dfrac{p(x|\theta)p(\theta)}{p(x)} = \dfrac{p(x|\theta)p(\theta)}{\int_{\theta'} p(x|\theta')p(\theta')}.$
    </p>

    <p>
        It takes two inputs, the <i>prior</i> $p(\theta)$, and the <i>likelihood</i> $p(x|\theta)$, and returns the posterior $p(\theta|x)$.
       Computing the output from the two inputs is easy to express, but expensive to compute due to the pesky integral, which generally doesn't admit a closed-form solution, and would require exponential computation in the support of $\theta$ to approximate.
       When $\theta$ represents all the weights and biases of a deep neural network, this simply isn't practical.
       For small networks however, we can use exact Bayesian inference; take a look at the demo below to build some intuitions around what's going on here.
    </p>

     <!-- Exact Inference figures -->
    <figure style="position:relative; width:984px; height:310px;">
        <div id="exact_train" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <figcaption id="exact_caption" style="position:relative; width: 420px; height: 10px; left: 540px; top: 10px;">
            Now we integrate out the of weights in proportion to the posterior.
        </figcaption>
    </figure>

    <figure style="position:relative; width:984px; height:400px;">
        <div id="exact_train_contour" style="position:relative; float:left; width: 320px; height: 320px;">
            <figcaption id="exact_train_loss_title" style="position:relative; text-align:center;right:10px">
                Training Loss
            </figcaption>
        </div>
        <div id="progress" style="position:relative; margin-left: 334px; width:650px; height:300px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <figcaption id="exact_caption" style="position:absolute; width: 470px; height: 60px; left: 510px; top: 310px;">
            The black line shows the validation loss of the average.
            Observe how validation loss decreases as one sample more and eventually becomes lower than MLE estimate in dark green and the local minimum in dark red.
        </figcaption>
        <button type="button" onclick="sampler.sample_train()">Sample</button>
        <button type="button" onclick="sampler.reset()">Clear</button>
    </figure>

   <!- SAY SOMETHING ABOUT THE INTERPRETATION OF THE PRIOR AND LIKELIHOOD HERE, AND ADD SOME ANALYSIS TO THE DEMO-> </p>
    <h3>Variational inference</h3>
    <p>
        We can scale up inference by settling for an approximate solution via <i>variational inference</i>.
        The API requires one additional argument, $q(\theta)$, called the <i>variational distribution</i>, and returns the <i>approximate posterior</i> $q^*(\theta)$ according to
        $$q^*(\theta) = \texttt{argmax} E_{q(\theta)} [ p(x|\theta) ] - D_{KL} [q(\theta)||p(\theta)].$$
        The solution is a good one when the approximate posterior $q(\theta)$ is close to the true posterior $p(\theta|x)$.
        We will use gradient-based optimization to solve the $\texttt{argmax}$ optimization, the same algorithm we used before to train our neural network.
   </p>

   <figure style="position:relative; width:800px; height:200px;">
       <div class="container" style="width: 800px;">
           <div id="svi-algo-box-left" style="display: table-cell;"></div>
           <div id="svi-algo-box-right" style="display: table-cell;"></div>
       </div>
   </figure>

    <pre id="hello-world-code">
    \begin{algorithmic}
    \PROCEDURE{SGD}{$x, y, w$}
        \WHILE {training not converged}
            \STATE $g = \text{BACKPROP}(x, y, w)$
            \STATE $w = w + \alpha g$
        \ENDWHILE
        \ENDPROCEDURE
    \end{algorithmic}
    </pre>

    <pre id="hello-world-code2">
    \begin{algorithmic}
    \PROCEDURE{SVI}{$x, y, w$}
        \WHILE {training not converged}
            \STATE ${\color{blue} \epsilon \sim \mathcal{N}(0, I)}$
            \STATE $g = \text{BACKPROP}(x, y, {\color{blue} w+\epsilon\sigma})$
            \STATE $w = w + \alpha g$
            \STATE ${\color{blue}\sigma = \sigma + \alpha\epsilon g}$
        \ENDWHILE
        \ENDPROCEDURE
    \end{algorithmic}
    </pre>

    <!-- end ec edit 2017-jan-21; i know this section is getting overly pedantic, but i'm not sure how best to introduce these concepts...-->

    <!-- <p> There are many possible strategies to try to avoid overfitting, generally called regularization methods.  Instead of choosing the weights that best fit to the training data, these methods try to balance data fit with the complexity of the function being learned.  With Bayesian neural network, first developed by <dt-cite key="neal1995bayesian"></dt-cite> and <dt-cite key="graves2011practical"></dt-cite>, which combines the power of a neural network with the flexibility of bayesian methods, we can fit the best set of weights and regularize at the same time.  </p> -->




   <h3>Variational Inference (old)</h3>
    <p>
        Variational inference means, loosely, fitting a nice, tractable distribution (such as a Gaussian, or a million Gaussians) to be as close as possible to the complicated, intractable posterior.
        Once we find a nice tractable distribution that approximates
        the intractable one, we can use the tractable distribution to make predictions or measure uncertainty within an tractable time complexity.
    </p>

    <p>
        Lets define $p$ as the true distribution and $q$ to be the million-gaussian we use to approximate $p$.
        We call it a variational distribution.
        We want $q$ to be close to $p$, but what does it mean for two probability distributions to be close to each other,
        in other words, if we define a loss function that describes the closeness of two distributions, what properties are desired? For starters, if $p = q$, the loss should be 0, also if $p$ and $q$ assign a different probability to the same point,
        we want to punish it by assigning a large loss.
        Kullback Leibler divergence is such a measure, PUT EQUATION AND HOW ITS ASYMMETRIC HERE.
    </p>

    <!-- KL divergence figure -->
    <figure style="position:relative; width:1100px; height:400px;">
        <div id="curve" style="position:relative; float:left; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <form style="position:relative; margin-left: 984px;" onclick="divergence_curve.update(getmean() - 6, sdScaler(getsd()))">
            <input type="radio" name="divergence_type" value="KL" checked> KL<br>
            <input type="radio" name="divergence_type" value="reverse KL"> reverse KL<br>
            <input type="radio" name="divergence_type" value="JS"> JS
        </form>
        <div id="slider3" style="position:absolute; width:300px; height: 50px; left:20px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Mean μ = 0.0</text>
        </div>
        <div id="slider4" style="position:absolute; width: 300px; height: 50px; left: 280px; top: 320px;">
            <text class="figtext" style="top: -5px; left: 20px; position: relative;">Standard Deviation = 1.0</text>
        </div>
        <figcaption id="Gaussiancaption" style="position:absolute; width: 420px; height: 90px; left: 540px; top: 320px;">
            If we were to optimize, we must know the objective. Here, the objective is a measure of differences in two probability distributions. The dark green area represents KL divergence, dark red is reverse KL, orange is Jensen Shannon divergence. Try to minimize
            the areas. Do these measures agree?
        </figcaption>
    </figure>

    <p>
        Using a variational method come with other perks as well: with a clearly defined, continuously differentiable objective, we could use gradient-based methods and optimizers off the shelf.
    </p>

    <!-- Variational Inference Layer -->
    <figure style="position:relative; width:984px; height:1075px;">
        <figcaption id="Var_inf_caption">
            Variational Inference
        </figcaption>
        <figcaption id="var_caption">
            Now we fit a distribution of weights to the underlying latent distribution.
        </figcaption>
        <div id="var_full" style="position:relative; width:984px; height:300px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <button type="button" onclick="bnn.train()">Train</button>
        <button type="button" onclick="bnn.sample()">Sample</button>
        <button type="button" onclick="bnn.reset()">Reset</button>

        <figcaption id="exact_caption" style="position:relative; width: 470px; height: 10px; left:500px">
            What if you sampled from the learned distribution?
        </figcaption>
        <div class="container" style="margin-top: 20px;">
            <div id="var_progress" style="display: table-cell; width:364px; height:200px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
            <div id="var_graph" style="display: table-cell; width:600px; height:200px;"></div>
        </div>

        <div class="container" style="margin-top: 20px;">
            <div id="var_loss_train" style="display: table-cell; width: 320px; height: 350px;">
                <figcaption id="var_loss_train_title" style="position:relative; text-align:center;right:10px">
                    Training Loss
                </figcaption>
            </div>
            <div style="display: table-cell; width: 320px; height: 350px;">
                <figcaption id="var_loss_caption" style="position: relative; width: 150px; left: 75px; right: 75px; top: 100px;">
                    The loss surface for the Variational Net. The training loss is plotted on the left, the validation loss is plotted on the right.
                </figcaption>
            </div>
            <div id="var_loss_valid" style="display: table-cell; width: 320px; height: 350px;">
                <figcaption id="var_loss_valid_title" style="position:relative; text-align:center;right:10px">
                    Test Loss
                </figcaption>
            </div>
        </div>
    </figure>
    <h3>Expression of Uncertainty</h3>
    <p>
    TODO: discuss the uncercatinty estimates you get for free by modeling the posterior.
    </p>
    <!-- VARIANCE FIGURE
        <figure style="position:relative; width:984px; height:350px;">
        <figcaption id="disagree">
            A Change in Perspective
        </figcaption>
        <div id="uncertain_mlp" style="position:relative; float:left; width:485px; height:300px; bottom: 10px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <div id="uncertain_bnn" style="position:relative; margin-left: 499px; width:485px; height:300px; bottom: 10px; border: 1px solid rgba(0, 0, 0, 0.05);"></div>
        <button type="button" name="uncertain_train" onclick="uncertainty.train()">Train</button>
        <button type="button" name="uncertain_reset" onclick="uncertainty.reset()">Reset</button>
    </figure> -->

    <!--
        HERE ARE SOME IDEAS FOR EXTRA STUFF TO TALK ABOUT, SPACE PERMITTING
    <h3>Automatic Differentiation Variational Inference</h3>
    <p>
        The reparameterization trick
        <dt-cite key="kingma2013autoencoding"></dt-cite>
        <dt-cite key="rezende2014stochastic"></dt-cite>

        ADVI
        <dt-cite key="kucukelbir2016automatic"></dt-cite>

        Bayes by backprop
        <dt-cite key="blundell2015weight"></dt-cite>
    </p>

    <H3>Connection to Dropout</H3>
    <p>
        Dropout can be seen as an approximation to stochastic variational inference, where we add weights that can turn off each unit entirely, and integrate out these weights.
        <dt-cite key="kingma2015variational"></dt-cite>
        <dt-cite key="gal2016dropout"></dt-cite>
    </p>

    <H3>Connection to Ensembles</H3>
    <p>
        asdf
    </p>

    <H3>Connection to Gradient Noise</H3>
    <p>
        asdf
    </p>
    -->
    <p>
        <!- ELLIOT Q: CAN WE FORMAT THIS LIKE A \citet IN LATEX? ->
        Our implementation is based on Karpathy 2015 <dt-cite key="karpathy2015convnetjs"></dt-cite>.
    </p>

    <script src="assets/lib/parameters.js"></script>
    <script src="assets/lib/plotter.js"></script>
    <script src="assets/lib/divergence.js"></script>
    <script src="assets/lib/contour_plot.js"></script>
    <script src="assets/lib/mlp.js"></script>
    <script src="assets/lib/bnn.js"></script>
    <script src="assets/lib/full_bnn.js"></script>
    <script src="assets/lib/uncertainty.js"></script>
    <script src="assets/lib/sampler.js"></script>
    <script src="assets/lib/net_lib.js"></script>
    <script src="assets/lib/seedrandom.min.js"></script>
    <script src="assets/iterates.js"></script>
    <script>
        // NN on sine
        var mlp = mlp(d3.select("#nn_full"), d3.select("#nn_loss_train"), d3.select("#nn_loss_valid"), d3.select('#nn_graph'));
        mlp.plot();

        // exact inference
        var sampler = sampler(d3.select("#exact_train"), d3.select("#exact_train_contour"), d3.select("#progress"));
        sampler.plot();

        //DIVERGENCES
        var divergence_curve = divergence(d3.select("#curve"), 0, 1);
        var sdScaler = d3.scaleLinear().domain([0, 4]).range([0.5, 2.5])

        var sliderc = sliderGen([230, 40])
            .ticks([0, 3, 6, 9, 12])
            .ticktitles(function(d, i) {
                return ["-6", "-3", "0", "3", "6"][i]
            })
            .change(function(i) {
                d3.select("#slider3").selectAll(".figtext").html("Mean μ = " + (getmean() - 6).toPrecision(2))
                divergence_curve.update(getmean() - 6, sdScaler(getsd()))
            })
            .startxval(6)
            .cRadius(7)
            .shifty(-12)
            .margins(20, 20)
        var sliderd = sliderGen([230, 40])
            .ticks([0, 1, 2, 3, 4])
            .ticktitles(function(d, i) {
                return ["0.5", "1", "1.5", "2", "2.5"][i]
            })
            .change(function(i) {
                d3.select("#slider4").selectAll(".figtext").html("Standard Deviation = " + sdScaler(getsd()).toPrecision(2))
                divergence_curve.update(getmean() - 6, sdScaler(getsd()))
            })
            .cRadius(7)
            .shifty(-12)
            .startxval(1)
            .margins(20, 20)

        var getmean = sliderc(d3.select("#slider3")).xval
        var getsd = sliderd(d3.select("#slider4")).xval
        divergence_curve.draw_line();

        // variational inference
        var bnn = bnn(d3.select("#var_full"), d3.select("#var_loss_train"), d3.select("#var_loss_valid"), d3.select("#var_progress"), d3.select("#var_graph"));

        // variational inference
        var full_bnn = full_bnn_view(d3.select("#full_bnn"), d3.select("#bnn_graph"));
        // full_bnn.train();

        // SGD algo box
       var code = document.getElementById("hello-world-code").textContent;
       var code2 = document.getElementById("hello-world-code2").textContent;
       var parent_left = document.getElementById("svi-algo-box-left");
       var parent_right = document.getElementById("svi-algo-box-right");
       var options = {
            lineNumber: true
        };
        pseudocode.render(code, parent_left, options);
        pseudocode.render(code2, parent_right, options);
    </script>
</dt-article>

<dt-appendix>

</dt-appendix>

<script>
    renderMathInElement(
        document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                },
                {
                    left: "\\\\",
                    right: "\\\\",
                    display: true
                },
                {
                    left: "\\",
                    right: "\\",
                    display: false
                },
            ]
        }
    );
</script>

<script type="text/bibliography">
    @inproceedings{graves2011practical, title={Practical variational inference for neural networks}, author={Graves, Alex}, booktitle={Advances in Neural Information Processing Systems}, pages={2348--2356}, year={2011} } @misc{karpathy2015convnetjs, title={ConvNetJS:
    Javascript library for deep learning}, author={Karpathy, A}, year={2015} } @phdthesis{neal1995bayesian, title={Bayesian learning for neural networks}, author={Neal, Radford M}, year={1995}, school={University of Toronto} } @article{kingma2013autoencoding,
    author = {Diederik P. Kingma and Max Welling}, title = {Auto-Encoding Variational Bayes}, journal = {International Conference on Learning Representations}, year = {2014} } @inproceedings{rezende2014stochastic, title={Stochastic Backpropagation and
    Approximate Inference in Deep Generative Models}, author={Rezende, Danilo J and Mohamed, Shakir and Wierstra, Daan}, booktitle={Proceedings of the 31st International Conference on Machine Learning}, pages={1278--1286}, year={2014} } @article{rumelhart1986learning,
    title={Learning representations by back-propagating errors}, author={Rumelhart, David E and Hinton, Geoffrey E}, journal={Nature}, volume={323}, pages={9}, year={1986} } @inproceedings{kingma2015adam, title={{Adam}: A Method for Stochastic Optimization},
    year={2015}, author={Kingma, Diederik and Ba, Jimmy}, booktitle={International Conference on Learning Representations}, } @article{hoffman2013stochastic, title={Stochastic variational inference}, author={Hoffman, Matthew D and Blei, David M and Wang,
    Chong and Paisley, John}, journal={The Journal of Machine Learning Research}, volume={14}, number={1}, pages={1303--1347}, year={2013} } @inproceedings{schulman2015gradient, title={Gradient estimation using stochastic computation graphs}, author={Schulman,
    John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter}, booktitle={Advances in Neural Information Processing Systems}, pages={3528--3536}, year={2015} } @phdthesis{speelpenning1980compiling, title={Compiling Fast Partial Derivatives of Functions
    Given by Algorithms}, author={Speelpenning, Bert}, year={1980}, school={University of Illinois at Urbana-Champaign} } @article{rall1981automatic, title={Automatic differentiation: Techniques and applications}, author={Rall, Louis B}, year={1981},
    publisher={Springer} } @article{robbins1951stochastic, title={A stochastic approximation method}, author={Robbins, Herbert and Monro, Sutton}, journal={The annals of mathematical statistics}, pages={400--407}, year={1951} } @article{kucukelbir2016automatic,
    title={Automatic Differentiation Variational Inference}, author={Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M}, journal={arXiv preprint arXiv:1603.00788}, year={2016} } @article{paisley2012variational,
    title={Variational Bayesian inference with stochastic search}, author={Paisley, John and Blei, David and Jordan, Michael}, journal={arXiv preprint arXiv:1206.6430}, year={2012} } @inproceedings{blundell2015weight, title={Weight Uncertainty in Neural
    Network}, author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan}, booktitle={International Conference on Machine Learning}, pages={1613--1622}, year={2015} } @inproceedings{gal2016dropout, title={Dropout as a Bayesian
    approximation: Representing model uncertainty in deep learning}, author={Gal, Yarin and Ghahramani, Zoubin}, booktitle={international conference on machine learning}, pages={1050--1059}, year={2016} } @inproceedings{kingma2015variational, title={Variational
    dropout and the local reparameterization trick}, author={Kingma, Diederik P and Salimans, Tim and Welling, Max}, booktitle={Advances in Neural Information Processing Systems}, pages={2575--2583}, year={2015} }
</script>
